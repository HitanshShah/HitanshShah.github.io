---
---


@inproceedings{10.1145/3615886.3627748,
author = {Malvi, Shrey and Shah, Hitansh and Chandarana, Niketan and Purohit, Mirali and Adler, Jacob and Kerner, Hannah},
title = {Automated Multi-class Crater Segmentation in Mars Orbital Images},
year = {2023},
isbn = {9798400703485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615886.3627748},
doi = {10.1145/3615886.3627748},
abstract = {Crater mapping and counting are critical analyses in many planetary science investigations, as the size-frequency distribution of impact craters can be used to measure the age of a planet's surface and interpret its geologic history. Crater counting is extremely tedious --- counting hundreds to thousands of small features in a small region could take days to months for a trained planetary scientist. Previous work has demonstrated the feasibility of using computer vision techniques to automatically map and count craters in Mars orbital images using semantic segmentation. We present an improved approach for binary and multi-class semantic segmentation of craters in THEMIS daytime thermal infrared images using U2-Net and U-NetFormer with template matching. Our approach is the first method to perform multi-class segmentation of craters using computer vision. Our binary segmentation approach outperforms previous approaches that used semantic segmentation and template matching. A new global high-resolution image mosaic dataset of Mars (CTX, 5 m/px) is now available, but to date, no studies have benchmarked automated crater counting methods for this improved dataset. Toward this goal, we applied the THEMIS-trained model to out-of-domain CTX datasets and evaluated results quantitatively using the DoMars16 benchmark dataset and qualitatively using global mosaic tiles. We show that the THEMIS-trained models effectively segment craters in CTX images without additional fine-tuning. The code can be found here.},
booktitle = {Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {110–120},
numpages = {11},
keywords = {Multi-class crater classification, U-Net, out-of-distribution evaluation, remote sensing, semantic segmentation, template matching},
location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
series = {GeoAI '23},
preview = {gusev.jpg},
bibtex_show = {true},
website={https://dl.acm.org/doi/abs/10.1145/3615886.3627748}
}

@inproceedings{pawade2021xai,
  title={Xai—an approach for understanding decisions made by neural network},
  author={Pawade, Dipti and Dalvi, Ashwini and Gopani, Jash and Kachaliya, Chetan and Shah, Hitansh and Shah, Hitanshu},
  booktitle={Recent Trends in Communication and Intelligent Systems: Proceedings of ICRTCIS 2020},
  pages={155--165},
  year={2021},
  organization={Springer},
  url={https://doi.org/10.1007/978-981-16-0167-5_17},
  abstract={A convolutional neural network (CNN) works on unstructured data such as images, audio clips and text to perform tasks of classification, detection, etc. It consists of two main parts, namely the convolutional part and the fully connected part. The first part uses filters to extract usable features from images. At preliminary levels, it involves textures and colours, and at forward layers involves complex features like eyes, beaks, ears, etc. The next part uses the identified features to make decisions. Neural networks provide better accuracy than conventional ML models. Unfortunately, their integral complexity and sophisticated nature do not make them much interpretable. Even with great accuracy, many high-stake decisions cannot be taken without human validation. One such case is the malaria detection system wherein pigmented blood cells of patients are examined. Just providing a positive or negative label is not sufficient, an explanation for the output is required. This paper presents an approach that extends over the existing local interpretable model agnostic explanations (LIME) that enables us to analyse neural network activations without potentially having to understand the underlying architecture. As an implementation of our approach, we look forward to explain an already built CNN classifier that classifies microscopic images of cells as being infected by the malarial parasite or not. This approach allows the examiner to go through the layers individually, observe neuron activations and detect parts of input image that trigger neurons the most to assess decision made by the neural network. The microscopic images of blood smears can have irregularities, and sometimes, although not that often, the blot on the smear might not be due to the presence of parasites, but just a pigment of the reagent used. We aim at providing what features or characteristics(parts of the input image) were in support of the decision provided by the network.},
  preview={XAI.jpg},
  bibtex_show={true},
  website={https://link.springer.com/chapter/10.1007/978-981-16-0167-5_17}
}