---
layout: page
title: Named Entity Recognition
description: Exploring different NLP models for Named Entity Recognition.
img: assets/img/NERC.png
importance: 2
category: academia
github: https://github.com/HitanshShah/named-entity-recognition
---
Created Using: <span class="badge" style="background-color: var(--global-theme-color); border-color: var(--global-theme-color) !important">Python</span> <span class="badge" style="background-color: var(--global-theme-color); border-color: var(--global-theme-color) !important">TensorFlow</span> <span class="badge" style="background-color: var(--global-theme-color); border-color: var(--global-theme-color) !important">Keras</span> <span class="badge" style="background-color: var(--global-theme-color); border-color: var(--global-theme-color) !important">PyTorch</span> <span class="badge" style="background-color: var(--global-theme-color); border-color: var(--global-theme-color) !important">Flask</span> <span class="badge" style="background-color: var(--global-theme-color); border-color: var(--global-theme-color) !important">ReactJS</span>

<i>The code for this project is available at: <a href="https://github.com/HitanshShah/named-entity-recognition">github.com/HitanshShah/named-entity-recognition</a>. Reach out to me via <a href="mailto:hitansh.shah@gmail.com">email</a> if you have any queries related to this project.</i>

Named Entities refer to the key subjects of a piece of text, such as names, locations, organizations, events, themes, topics, and so on. Named Entity Recognition (NER) is a Natural Language Processing (NLP) method that extracts this information from text. NER is regarded as a basis for information extraction and can be applied to more complex data processing tasks like sentiment evaluation and modeling of topics.

<div class="row">
    <div class="col-sm-8 mt-3 mt-md-0 mx-auto">
        {% include figure.liquid loading="eager" path="assets/img/NERC.png" title="Overall structure of the NER system" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Overall structure of the NER system.
</div>

<strong>Models for Named Entity Recognition:</strong>
<ul>
    <li><strong>Conditional Random Field (CRF): </strong>CRFs enabled the modeling of dependencies between sequential labels, allowing for accurate identification of named entities in text data. By leveraging CRFs, the system achieved superior performance in identifying entities such as persons, organizations, and locations within unstructured text.</li>
    <li><strong>BERT + CRF: </strong>BERT (Bidirectional Encoder Representations from Transformers) is a language model developed by Google to solve NLP tasks like sentiment analysis, NER, question answering using deep learning constructs, and so on. To enhance NER accuracy, we integrated BERT with a Conditional Random Field (CRF) to consider neighboring decisions. This approach combined BERT's contextual understanding with CRF's structured predictions, achieving superior performance in identifying named entities within text data.</li>
    <li><strong>BiLSTM + CRF: </strong>BiLSTM (Bidirectional Long Short-Term Memory) processes input sequences bidirectionally, capturing past and future information effectively for variable-length sentences. CRF addresses the limitation of BiLSTM in capturing label dependencies, resulting in improved performance for NER. This approach utilizes pre-trained word embeddings alongside character-level embeddings generated by a CNN, feeding into BiLSTM for sequence processing. Furthermore, enhancements with ELMo embeddings, derived from a deep bidirectional language model, combined with CRF, provide robust label dependency modeling during inference.</li>
    <li><strong>Flair (FLERT Approach): </strong>FLAIR, developed by Zalando Research, offers a PyTorch-based NLP framework. FLERT, a component within FLAIR, enhances Named Entity Recognition (NER) by leveraging entity retrieval and typing. It preprocesses text using a combination of pre-trained embeddings like contextual string embeddings (CSE), GloVe, and FastText, feeding them into a linear chain Conditional Random Field (CRF) for prediction. FLERT also supports fine-tuning embeddings for domain-specific improvements.</li>
    <li><strong>Automated Concatenation of Embeddings (ACE): </strong>ACE is an approach to automate the process of finding better concatenations of embeddings for structured prediction tasks. The ACE approach involves defining a search space of possible combinations of embeddings, training a controller to select the best combination for a given task, and evaluating the performance of different combinations on a validation set. Overall, the ACE approach provides an automated way to search for better embedding concatenations for structured prediction tasks.</li>
</ul>

We trained and evaluated all of these 4 models on the CoNLL-2003 dataset, which was extracted from Reuters Corpus. This dataset contains NER tags for 4 categories: <code>Person</code>, <code>Location</code>, <code>Organization</code> and <code>Miscellaneous</code>.
After training the above mentioned models, we created <code>Flask APIs</code> for all of them and created a user-interface using <code>ReactJS</code> that would allow users to enter some text and choose a model for performing Named Entity Recognition.

<strong>NER results for each of the models</strong>

<strong>BERT + CRF</strong>
<div class="row">
    <div class="col-sm mt-3 mt-md-0 mx-auto">
        {% include figure.liquid loading="eager" path="assets/img/bertCrf.png" title="NER using BERT + CRF" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

<strong>BiLSTM + CRF</strong>
<div class="row">
    <div class="col-sm mt-3 mt-md-0 mx-auto">
        {% include figure.liquid loading="eager" path="assets/img/BiLSTM.png" title="NEW using BiLSTM + CRF" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

<strong>Flair</strong>
<div class="row">
    <div class="col-sm mt-3 mt-md-0 mx-auto">
        {% include figure.liquid loading="eager" path="assets/img/Flair.png" title="NER using Flair" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

<strong>Automated Concatenation of Encodings (ACE)</strong>
<div class="row">
    <div class="col-sm mt-3 mt-md-0 mx-auto">
        {% include figure.liquid loading="eager" path="assets/img/ace.png" title="NER using ACE" class="img-fluid rounded z-depth-1" %}
    </div>
</div>